{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " day4_done.py",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshal-ugale/john_wick/blob/master/day4_done_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0LjzFUDWv_8",
        "colab_type": "text"
      },
      "source": [
        "#Voice to text Conversion.!\n",
        "![alt text](https://lh3.googleusercontent.com/BWuNpqk7VQHC-vODFWs57VXteZvBvhNV4VtbBsA7WhuZZAeTPEZL3xfjskOIs_MFXf2hsLugyA=w640-h400-e365)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFdxtNv1Wv_D",
        "colab_type": "text"
      },
      "source": [
        "#Running or Importing .py Files with Google Colab to mount Drive on colab.\n",
        "\n",
        "Run these codes first in order to install the necessary libraries and perform authorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM389w2vWbaZ",
        "colab_type": "code",
        "outputId": "90cde709-87cd-47ba-a3c3-cce40d14c508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxIbB95pW-YS",
        "colab_type": "text"
      },
      "source": [
        "Now you can reach you Google Drive with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U2SRPamXIBN",
        "colab_type": "code",
        "outputId": "35df2bbb-3d90-46c5-da65-4e85f47d7bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLLtecC2XT4f",
        "colab_type": "text"
      },
      "source": [
        "# Copying the utilities and audio_path files to the 'jw' folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUs3CsELXcr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/'My Drive'/utilities /content/jw/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3x78NYsX8CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/drive/'My Drive'/validated_audio_data/voices_recorded /content/jw/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjgIaiDFYLU6",
        "colab_type": "text"
      },
      "source": [
        "#Installing virtual enviorment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fFOmUBBYPFE",
        "colab_type": "code",
        "outputId": "1c9c0174-45d7-451a-883c-79b0ec3bd44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "!pip3 install virtualenv\n",
        "!virtualenv theanoEnv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/77/6a86ef945ad39aae34aed4cc1ae4a2f941b9870917a974ed7c5b6f137188/virtualenv-16.7.8-py2.py3-none-any.whl (3.4MB)\n",
            "\r\u001b[K     |                                | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |▏                               | 20kB 1.7MB/s eta 0:00:02\r\u001b[K     |▎                               | 30kB 2.5MB/s eta 0:00:02\r\u001b[K     |▍                               | 40kB 1.6MB/s eta 0:00:03\r\u001b[K     |▌                               | 51kB 2.0MB/s eta 0:00:02\r\u001b[K     |▋                               | 61kB 2.4MB/s eta 0:00:02\r\u001b[K     |▊                               | 71kB 2.8MB/s eta 0:00:02\r\u001b[K     |▉                               | 81kB 3.1MB/s eta 0:00:02\r\u001b[K     |▉                               | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |█                               | 102kB 2.7MB/s eta 0:00:02\r\u001b[K     |█                               | 112kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▏                              | 122kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▎                              | 133kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▍                              | 143kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▌                              | 153kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▋                              | 163kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▋                              | 174kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▊                              | 184kB 2.7MB/s eta 0:00:02\r\u001b[K     |█▉                              | 194kB 2.7MB/s eta 0:00:02\r\u001b[K     |██                              | 204kB 2.7MB/s eta 0:00:02\r\u001b[K     |██                              | 215kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▏                             | 225kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▎                             | 235kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▍                             | 245kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▍                             | 256kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▌                             | 266kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▋                             | 276kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▊                             | 286kB 2.7MB/s eta 0:00:02\r\u001b[K     |██▉                             | 296kB 2.7MB/s eta 0:00:02\r\u001b[K     |███                             | 307kB 2.7MB/s eta 0:00:02\r\u001b[K     |███                             | 317kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▏                            | 327kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▎                            | 337kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▎                            | 348kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▍                            | 358kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▌                            | 368kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▋                            | 378kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▊                            | 389kB 2.7MB/s eta 0:00:02\r\u001b[K     |███▉                            | 399kB 2.7MB/s eta 0:00:02\r\u001b[K     |████                            | 409kB 2.7MB/s eta 0:00:02\r\u001b[K     |████                            | 419kB 2.7MB/s eta 0:00:02\r\u001b[K     |████                            | 430kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▏                           | 440kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▎                           | 450kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▍                           | 460kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▌                           | 471kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▋                           | 481kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▊                           | 491kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▉                           | 501kB 2.7MB/s eta 0:00:02\r\u001b[K     |████▉                           | 512kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████                           | 522kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████                           | 532kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▏                          | 542kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▎                          | 552kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▍                          | 563kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▌                          | 573kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▋                          | 583kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▋                          | 593kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▊                          | 604kB 2.7MB/s eta 0:00:02\r\u001b[K     |█████▉                          | 614kB 2.7MB/s eta 0:00:02\r\u001b[K     |██████                          | 624kB 2.7MB/s eta 0:00:02\r\u001b[K     |██████                          | 634kB 2.7MB/s eta 0:00:02\r\u001b[K     |██████▏                         | 645kB 2.7MB/s eta 0:00:02\r\u001b[K     |██████▎                         | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 778kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 788kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 798kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 808kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 819kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 829kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 839kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 849kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 860kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 870kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 880kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 890kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 901kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 911kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 921kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 931kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 942kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 952kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 962kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 972kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 983kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 993kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 2.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 2.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 2.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 2.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 2.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 2.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.7MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.8MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.9MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 3.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 3.4MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: virtualenv\n",
            "Successfully installed virtualenv-16.7.8\n",
            "Using base prefix '/usr'\n",
            "New python executable in /content/theanoEnv/bin/python3\n",
            "Also creating executable in /content/theanoEnv/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uISJBt6UZNiu",
        "colab_type": "text"
      },
      "source": [
        "#Creating virtual enviorment and activating the enviorment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5PYuVWFZNQW",
        "colab_type": "code",
        "outputId": "2cdf8a50-846e-4305-ea4a-1200b2054e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!virtualenv /content/Ds   #here deepspeech is edited to Ds.\n",
        "!source /content/Ds/bin/activate"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using base prefix '/usr'\n",
            "New python executable in /content/Ds/bin/python3\n",
            "Also creating executable in /content/Ds/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xj5jAuAZVfy",
        "colab_type": "text"
      },
      "source": [
        "#Installing DeepsSpeech-gpu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zl52Oq-ZVSi",
        "colab_type": "code",
        "outputId": "0b9b1786-c3b6-417d-82ee-7f26bafc4a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip3 install deepspeech-gpu\n",
        "#!pip3 install --upgrade deepspeech-gpu"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/10/288593c577f0d2b2152058286ec4c6284930df38756f5f2e9f1155e66ecc/deepspeech_gpu-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (18.7MB)\n",
            "\u001b[K     |████████████████████████████████| 18.7MB 421kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-gpu) (1.15.4)\n",
            "Installing collected packages: deepspeech-gpu\n",
            "Successfully installed deepspeech-gpu-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YNJWjLPZdeJ",
        "colab_type": "text"
      },
      "source": [
        "# Clone the deepspeech repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHRmxI-mZdO5",
        "colab_type": "code",
        "outputId": "44e193f3-489e-42d7-8694-252419da7bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone https://github.com/mozilla/DeepSpeech"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 14850 (delta 11), reused 6 (delta 1), pack-reused 14831\u001b[K\n",
            "Receiving objects: 100% (14850/14850), 46.39 MiB | 11.94 MiB/s, done.\n",
            "Resolving deltas: 100% (9846/9846), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krDKWOhjZidS",
        "colab_type": "text"
      },
      "source": [
        "# Installing requirement.txt dependencies using pip3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-a36-ebZi6g",
        "colab_type": "code",
        "outputId": "c9aab157-1b61-4230-ffee-1169d1fc73a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd DeepSpeech\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'DeepSpeech'\n",
            "/content/DeepSpeech\n",
            "Requirement already satisfied: tensorflow-gpu==1.14.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: numpy==1.15.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.15.4)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
            "Requirement already satisfied: pyxdg in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.26)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (42.0.1)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (2.0.10)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (1.3.7)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (2.21.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 21)) (0.6.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (0.10.3.post1)\n",
            "Requirement already satisfied: paramiko>=2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 25)) (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 26)) (1.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 27)) (3.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->-r requirements.txt (line 19)) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 20)) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 20)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 20)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 20)) (3.0.4)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (0.40.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (2.1.8)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (0.14.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (4.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 21)) (0.21.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->-r requirements.txt (line 22)) (1.13.2)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.1->-r requirements.txt (line 25)) (2.8)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.1->-r requirements.txt (line 25)) (3.1.7)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.1->-r requirements.txt (line 25)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 27)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 27)) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 27)) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->-r requirements.txt (line 21)) (0.30.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 22)) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_2qheRfZwkv",
        "colab_type": "text"
      },
      "source": [
        "#Install ds_ctcdecoder python package. ds_ctcdecoder is used to decode deepspeech model output(audio) to text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sweuXWSaULR",
        "colab_type": "code",
        "outputId": "2b2330b8-3fcd-4b57-e2ae-589b436c5575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip3 install $(python3 util/taskcluster.py --decoder)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ds-ctcdecoder==0.6.0\n",
            "\u001b[?25l  Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.6.0.cpu-ctc/artifacts/public/ds_ctcdecoder-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 16.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from ds-ctcdecoder==0.6.0) (1.15.4)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-oyluPhbPg3",
        "colab_type": "text"
      },
      "source": [
        "creating train.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qAIevKbbP5V",
        "colab_type": "code",
        "outputId": "199bad91-994c-474c-aa1e-f39f86224b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "! python /content/jw/utilities/support_scripts/createCSV.py --audio_path \"/content/jw/voices_recorded/train_data/\" --csv_output_path '/content/jw/data1/train/'  --csv_file_name 'train.csv'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "totalFiles=118\n",
            "Successfully created CSV file train.csv at /content/jw/data1/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXW2r4qmckNN",
        "colab_type": "text"
      },
      "source": [
        "creating test.csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNgYWFfzckut",
        "colab_type": "code",
        "outputId": "22468b2a-17e2-4d5d-9846-1a86aa51088f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "! python /content/jw/utilities/support_scripts/createCSV.py --audio_path \"/content/jw/voices_recorded/test_data/\" --csv_output_path '/content/jw/data1/test/'  --csv_file_name 'test.csv'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "totalFiles=17\n",
            "Successfully created CSV file test.csv at /content/jw/data1/test/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zch9OI2dclL1",
        "colab_type": "text"
      },
      "source": [
        "Creating Dev.csv File."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lusOeBh7clj1",
        "colab_type": "code",
        "outputId": "abf07fae-8790-4010-a1f7-0d35f1fe8b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "! python /content/jw/utilities/support_scripts/createCSV.py --audio_path \"/content/jw/voices_recorded/dev_data/\" --csv_output_path '/content/jw/data1/dev/'  --csv_file_name 'dev.csv'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "totalFiles=34\n",
            "Successfully created CSV file dev.csv at /content/jw/data1/dev/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEretNUhISg",
        "colab_type": "text"
      },
      "source": [
        "# GenerateLMtext.py file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oID6EQP3hIF6",
        "colab_type": "code",
        "outputId": "7e6212be-81c1-4689-f824-3e0d30251453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!python /content/jw/utilities/support_scripts/generateLMText.py --audio_path \"/content/jw/voices_recorded/\" --lm_output_path '/content/jw/lm_word/' --lm_file_name 'word.txt'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "totalFiles=169\n",
            "Successfully created lm file word.txt at /content/jw/lm_word/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGlpFAgjvi0",
        "colab_type": "text"
      },
      "source": [
        "#kenLM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm5WFjUnjvUF",
        "colab_type": "code",
        "outputId": "02d412a0-17ed-4253-db92-e2454e80f48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd native_client\n",
        "%rm -rf kenlm \\\n",
        "    && git clone --depth 1 https://github.com/kpu/kenlm && cd kenlm \\\n",
        "    && mkdir -p build \\\n",
        "    && cd build \\\n",
        "    && cmake .. \\\n",
        "    && make -j 4\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech/native_client\n",
            "Cloning into 'kenlm'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (312/312), done.\u001b[K\n",
            "remote: Compressing objects: 100% (300/300), done.\u001b[K\n",
            "remote: Total 312 (delta 9), reused 73 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (312/312), 483.90 KiB | 910.00 KiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "-- The C compiler identification is GNU 7.4.0\n",
            "-- The CXX compiler identification is GNU 7.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   program_options\n",
            "--   system\n",
            "--   thread\n",
            "--   unit_test_framework\n",
            "--   chrono\n",
            "--   date_time\n",
            "--   atomic\n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.6\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/include (found version \"5.2.2\") \n",
            "-- Could NOT find Eigen3 (missing: EIGEN3_INCLUDE_DIR EIGEN3_VERSION_OK) (Required is at least version \"2.91.0\")\n",
            "CMake Warning at lm/interpolate/CMakeLists.txt:65 (message):\n",
            "  Not building interpolation.  Eigen3 was not found.\n",
            "\n",
            "\n",
            "-- To install Eigen3 in your home directory, copy paste this:\n",
            "export EIGEN3_ROOT=$HOME/eigen-eigen-07105f7124f9\n",
            "(cd $HOME; wget -O - https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2 |tar xj)\n",
            "rm CMakeCache.txt\n",
            "\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DeepSpeech/native_client/kenlm/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_filter\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_util\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 12%] Built target kenlm_filter\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 28%] Built target kenlm_util\n",
            "\u001b[35m\u001b[1mScanning dependencies of target string_stream_test\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target joint_sort_test\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target probing_hash_table_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target read_compressed_test\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object util/CMakeFiles/string_stream_test.dir/string_stream_test.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object util/CMakeFiles/joint_sort_test.dir/joint_sort_test.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object util/CMakeFiles/read_compressed_test.dir/read_compressed_test.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32m\u001b[1mLinking CXX executable ../tests/joint_sort_test\u001b[0m\n",
            "[ 31%] Built target joint_sort_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target bit_packing_test\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/bit_packing_test.dir/bit_packing_test.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32m\u001b[1mLinking CXX executable ../tests/read_compressed_test\u001b[0m\n",
            "[ 33%] Built target read_compressed_test\n",
            "[ 34%] \u001b[32m\u001b[1mLinking CXX executable ../tests/string_stream_test\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target tokenize_piece_test\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/tokenize_piece_test.dir/tokenize_piece_test.cc.o\u001b[0m\n",
            "[ 35%] Built target string_stream_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sorted_uniform_test\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/sorted_uniform_test.dir/sorted_uniform_test.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 36%] Built target probing_hash_table_benchmark\n",
            "\u001b[35m\u001b[1mScanning dependencies of target integer_to_string_test\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/integer_to_string_test.dir/integer_to_string_test.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX executable ../tests/bit_packing_test\u001b[0m\n",
            "[ 38%] Built target bit_packing_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target file_piece_test\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object util/CMakeFiles/file_piece_test.dir/file_piece_test.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32m\u001b[1mLinking CXX executable ../tests/tokenize_piece_test\u001b[0m\n",
            "[ 39%] Built target tokenize_piece_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pcqueue_test\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object util/CMakeFiles/pcqueue_test.dir/pcqueue_test.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32m\u001b[1mLinking CXX executable ../tests/sorted_uniform_test\u001b[0m\n",
            "[ 40%] Built target sorted_uniform_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target multi_intersection_test\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object util/CMakeFiles/multi_intersection_test.dir/multi_intersection_test.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX executable ../tests/integer_to_string_test\u001b[0m\n",
            "[ 42%] Built target integer_to_string_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target probing_hash_table_test\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_test.dir/probing_hash_table_test.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32m\u001b[1mLinking CXX executable ../tests/pcqueue_test\u001b[0m\n",
            "[ 45%] \u001b[32m\u001b[1mLinking CXX executable ../tests/file_piece_test\u001b[0m\n",
            "[ 45%] Built target pcqueue_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sized_iterator_test\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object util/CMakeFiles/sized_iterator_test.dir/sized_iterator_test.cc.o\u001b[0m\n",
            "[ 46%] Built target file_piece_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target io_test\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object util/stream/CMakeFiles/io_test.dir/io_test.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32m\u001b[1mLinking CXX executable ../tests/multi_intersection_test\u001b[0m\n",
            "[ 48%] Built target multi_intersection_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target stream_test\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object util/stream/CMakeFiles/stream_test.dir/stream_test.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32m\u001b[1mLinking CXX executable ../tests/probing_hash_table_test\u001b[0m\n",
            "[ 49%] Built target probing_hash_table_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target rewindable_stream_test\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object util/stream/CMakeFiles/rewindable_stream_test.dir/rewindable_stream_test.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../tests/sized_iterator_test\u001b[0m\n",
            "[ 50%] Built target sized_iterator_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sort_test\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object util/stream/CMakeFiles/sort_test.dir/sort_test.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/io_test\u001b[0m\n",
            "[ 52%] Built target io_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/stream_test\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 56%] Built target stream_test\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/rewindable_stream_test\u001b[0m\n",
            "[ 59%] Built target rewindable_stream_test\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/sort_test\u001b[0m\n",
            "[ 63%] Built target sort_test\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "\u001b[35m\u001b[1mScanning dependencies of target fragment\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target query\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_benchmark\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target build_binary\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 75%] Built target fragment\n",
            "\u001b[35m\u001b[1mScanning dependencies of target partial_test\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/partial_test.dir/partial_test.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 76%] Built target build_binary\n",
            "\u001b[35m\u001b[1mScanning dependencies of target left_test\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object lm/CMakeFiles/left_test.dir/left_test.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 78%] Built target query\n",
            "\u001b[35m\u001b[1mScanning dependencies of target model_test\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object lm/CMakeFiles/model_test.dir/model_test.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../tests/partial_test\u001b[0m\n",
            "[ 80%] Built target partial_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target model_buffer_test\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/common/CMakeFiles/model_buffer_test.dir/model_buffer_test.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/model_buffer_test\u001b[0m\n",
            "[ 82%] Built target model_buffer_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target kenlm_builder\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32m\u001b[1mLinking CXX executable ../tests/left_test\u001b[0m\n",
            "[ 83%] Built target left_test\n",
            "\u001b[35m\u001b[1mScanning dependencies of target phrase_table_vocab\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 86%] Built target phrase_table_vocab\n",
            "\u001b[35m\u001b[1mScanning dependencies of target filter\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 88%] Built target kenlm_benchmark\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX executable ../tests/model_test\u001b[0m\n",
            "[ 91%] Built target model_test\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 92%] Built target filter\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 93%] Built target kenlm_builder\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lmplz\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target count_ngrams\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target corpus_count_test\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target adjust_counts_test\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/corpus_count_test.dir/corpus_count_test.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/adjust_counts_test.dir/adjust_counts_test.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/adjust_counts_test\u001b[0m\n",
            "[ 97%] Built target adjust_counts_test\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../tests/corpus_count_test\u001b[0m\n",
            "[ 98%] Built target corpus_count_test\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 99%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akDqafq9sEcW",
        "colab_type": "text"
      },
      "source": [
        "#Generate words.arpa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBpPfIRQsEQb",
        "colab_type": "code",
        "outputId": "64bc6bca-7f79-4d53-f7d8-8aa8f475a87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "!/content/DeepSpeech/native_client/kenlm/build/bin/lmplz --text /content/jw/utilities/vocab.txt  --arpa /content/jw/arpa/words.arpa --o 5 --discount_fallback"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/jw/utilities/vocab.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "tcmalloc: large alloc 1923358720 bytes == 0x5648a0764000 @  0x7f415259f1e7 0x56489dcc8932 0x56489dc5d188 0x56489dc3c016 0x56489dc2817e 0x7f4150738b97 0x56489dc29bca\n",
            "tcmalloc: large alloc 8975663104 bytes == 0x5649131a6000 @  0x7f415259f1e7 0x56489dcc8932 0x56489dcb358a 0x56489dcb3fa8 0x56489dc3c033 0x56489dc2817e 0x7f4150738b97 0x56489dc29bca\n",
            "****************************************************************************************************\n",
            "Unigram tokens 20364 types 1693\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:20316 2:1065772288 3:1998323072 4:3197316864 5:4662753792\n",
            "tcmalloc: large alloc 4662755328 bytes == 0x5648a0764000 @  0x7f415259f1e7 0x56489dcc8932 0x56489dcb358a 0x56489dcb3fa8 0x56489dc3c5dd 0x56489dc2817e 0x7f4150738b97 0x56489dc29bca\n",
            "tcmalloc: large alloc 1998323712 bytes == 0x5649f5e9e000 @  0x7f415259f1e7 0x56489dcc8932 0x56489dcb358a 0x56489dcb3fa8 0x56489dc3c9c5 0x56489dc2817e 0x7f4150738b97 0x56489dc29bca\n",
            "tcmalloc: large alloc 3197321216 bytes == 0x564b2aa26000 @  0x7f415259f1e7 0x56489dcc8932 0x56489dcb358a 0x56489dcb3fa8 0x56489dc3c9c5 0x56489dc2817e 0x7f4150738b97 0x56489dc29bca\n",
            "Statistics:\n",
            "1 1693 D1=0.535168 D2=1.30815 D3+=1.41492\n",
            "2 9643 D1=0.763263 D2=1.17939 D3+=1.62429\n",
            "3 14504 D1=0.884085 D2=1.24925 D3+=1.65213\n",
            "4 15665 D1=0.936283 D2=1.37642 D3+=2.304\n",
            "5 15137 D1=0.9485 D2=1.24699 D3+=1.75965\n",
            "Memory estimate for binary LM:\n",
            "type      kB\n",
            "probing 1242 assuming -p 1.5\n",
            "probing 1482 assuming -r models -p 1.5\n",
            "trie     545 without quantization\n",
            "trie     281 assuming -q 8 -b 8 quantization \n",
            "trie     511 assuming -a 22 array pointer compression\n",
            "trie     247 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Chain sizes: 1:20316 2:154288 3:290080 4:375960 5:423836\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "\r----------------------------------------------------------------------------------------------------\r++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r****************************************************************************************************\r####################################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:20316 2:154288 3:290080 4:375960 5:423836\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "\r----------------------------------------------------------------------------------------------------\r++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r****************************************************************************************************\r####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "\r----------------------------------------------------------------------------------------------------\r++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:14216172 kB\tVmRSS:1902540 kB\tRSSMax:1920900 kB\tuser:0.166996\tsys:0.950291\tCPU:1.11733\treal:1.10581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEjHhc7RyiaG",
        "colab_type": "text"
      },
      "source": [
        "#Genrate lm.binary from words.arpa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buPfh4fNyiKK",
        "colab_type": "code",
        "outputId": "5f4440b7-d3e6-48ef-a27c-60ee6b5e4d50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!/content/DeepSpeech/native_client/kenlm/build/bin/build_binary -T -s /content/jw/arpa/words.arpa /content/jw/lmbinary/lm.binary"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading /content/jw/arpa/words.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "SUCCESS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqXqQoHR0E9E",
        "colab_type": "text"
      },
      "source": [
        "#Generating generate_trie floder using taskcluster.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTd-hit-0Er-",
        "colab_type": "code",
        "outputId": "0594f423-1970-4417-faee-2c274e849ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!python3 /content/DeepSpeech/util/taskcluster.py --target /content/DeepSpeech/native_client/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.6.0.cpu/artifacts/public/native_client.tar.xz ...\n",
            "Downloading: 100%\n",
            "\n",
            "generate_trie\n",
            "libdeepspeech.so\n",
            "LICENSE\n",
            "deepspeech\n",
            "deepspeech.h\n",
            "README.mozilla\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaYwUil61Ixi",
        "colab_type": "text"
      },
      "source": [
        "#Generating trie file using alphabet.txt and lm.binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w8QFs881Iia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!/content/DeepSpeech/native_client/generate_trie /content/jw/utilities/lm_text/alphabet.txt /content/jw/lmbinary/lm.binary /content/jw/trie/trie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmWABUiS2keu",
        "colab_type": "text"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSY2fHgysa7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "107ad9f2-d8f4-4e98-9cd7-4b3be181732a"
      },
      "source": [
        "%cd /content/DeepSpeech/"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTgLDg1a79wN",
        "colab_type": "text"
      },
      "source": [
        "give permission to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfnQ1Im8rse2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 777 /content/jw/utilities/test_train_script/train_deepspeech.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXsvcGbOr4Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee1794a4-66b7-4e5d-ddf2-b1bdc5388a8a"
      },
      "source": [
        "!/content/jw/utilities/test_train_script/train_deepspeech.sh"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ [ ! -f DeepSpeech.py ]\n",
            "+ python -u DeepSpeech.py --train_files /content/jw/data1/train/train.csv --dev_files /content/jw/data1/dev/dev.csv --test_files /content/jw/data1/test/test.csv --n_hidden 512 --epochs 70 --dropout_rate 0.22 --learning_rate 0.0001 --report_count 10000 --noearly_stop --export_dir /content/jw/result/export_data/ --checkpoint_dir /content/jw/result/checkpoint/ --alphabet_config_path /content/jw/utilities/lm_text/alphabet.txt --summary_dir /content/jw/utilities/support_scripts/ --lm_binary_path /content/jw/lmbinary/lm.binary --lm_trie_path /content/jw/trie/trie\n",
            "/bin/sh: 1: sox: not found\n",
            "SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1205 06:36:35.257466 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "W1205 06:36:35.362946 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "W1205 06:36:35.363338 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "W1205 06:36:35.363554 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "I1205 06:36:36.460555 140438052673408 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1205 06:36:36.905701 140438052673408 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1205 06:36:36.908828 140438052673408 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From DeepSpeech.py:234: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1205 06:36:37.677761 140438052673408 deprecation.py:323] From DeepSpeech.py:234: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I Initializing variables...\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 118 | Loss: 123.791869    \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 110.506444 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 110.506444 to: /content/jw/result/checkpoint/best_dev-118\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 107.717805    \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 109.301672 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1205 06:37:05.841157 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I Saved new best validating model with loss 109.301672 to: /content/jw/result/checkpoint/best_dev-236\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 106.365877    \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 109.223700 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 109.223700 to: /content/jw/result/checkpoint/best_dev-354\n",
            "Epoch 3 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 104.736403    \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 106.870699 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 106.870699 to: /content/jw/result/checkpoint/best_dev-472\n",
            "Epoch 4 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 102.616217    \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 105.916188 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 105.916188 to: /content/jw/result/checkpoint/best_dev-590\n",
            "Epoch 5 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 100.036471    \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 104.003670 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 104.003670 to: /content/jw/result/checkpoint/best_dev-708\n",
            "Epoch 6 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 97.756425     \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 102.176699 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 102.176699 to: /content/jw/result/checkpoint/best_dev-826\n",
            "Epoch 7 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 95.289869     \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 99.250366 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 99.250366 to: /content/jw/result/checkpoint/best_dev-944\n",
            "Epoch 8 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 92.355289     \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 99.480539 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 9 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 89.747980     \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.838167 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 94.838167 to: /content/jw/result/checkpoint/best_dev-1180\n",
            "Epoch 10 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 86.936693    \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.315658 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 94.315658 to: /content/jw/result/checkpoint/best_dev-1298\n",
            "Epoch 11 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 84.257895    \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 92.706703 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 92.706703 to: /content/jw/result/checkpoint/best_dev-1416\n",
            "Epoch 12 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 80.909569    \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 93.374292 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 13 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 77.950983    \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 91.694239 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 91.694239 to: /content/jw/result/checkpoint/best_dev-1652\n",
            "Epoch 14 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 74.399210    \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 89.010297 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 89.010297 to: /content/jw/result/checkpoint/best_dev-1770\n",
            "Epoch 15 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 71.625291    \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 87.885342 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 87.885342 to: /content/jw/result/checkpoint/best_dev-1888\n",
            "Epoch 16 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 68.008377    \n",
            "Epoch 16 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 85.503646 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 85.503646 to: /content/jw/result/checkpoint/best_dev-2006\n",
            "Epoch 17 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 63.947582    \n",
            "Epoch 17 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 83.291210 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 83.291210 to: /content/jw/result/checkpoint/best_dev-2124\n",
            "Epoch 18 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 60.483509    \n",
            "Epoch 18 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 80.073889 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 80.073889 to: /content/jw/result/checkpoint/best_dev-2242\n",
            "Epoch 19 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 56.967274    \n",
            "Epoch 19 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 78.531766 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 78.531766 to: /content/jw/result/checkpoint/best_dev-2360\n",
            "Epoch 20 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 53.224842    \n",
            "Epoch 20 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 74.804502 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 74.804502 to: /content/jw/result/checkpoint/best_dev-2478\n",
            "Epoch 21 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 50.890615    \n",
            "Epoch 21 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 73.543766 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 73.543766 to: /content/jw/result/checkpoint/best_dev-2596\n",
            "Epoch 22 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 46.455177    \n",
            "Epoch 22 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 72.028254 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 72.028254 to: /content/jw/result/checkpoint/best_dev-2714\n",
            "Epoch 23 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 43.534662    \n",
            "Epoch 23 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 74.253859 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 24 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 40.267594    \n",
            "Epoch 24 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 78.507730 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 25 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 37.348661    \n",
            "Epoch 25 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 81.853437 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 26 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 34.541188    \n",
            "Epoch 26 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 78.910133 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 27 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 30.780010    \n",
            "Epoch 27 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 81.888059 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 28 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 28.441917    \n",
            "Epoch 28 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 86.145706 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 29 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 27.024680    \n",
            "Epoch 29 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 79.877209 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 30 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 25.002666    \n",
            "Epoch 30 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 89.918557 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 31 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 22.465090    \n",
            "Epoch 31 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.908238 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 32 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 21.110540    \n",
            "Epoch 32 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 82.348746 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 33 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 19.416421    \n",
            "Epoch 33 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.669941 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 34 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 18.836612    \n",
            "Epoch 34 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 86.600251 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 35 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 19.294443    \n",
            "Epoch 35 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.644601 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 36 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 16.670501    \n",
            "Epoch 36 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.810015 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 37 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 16.127435    \n",
            "Epoch 37 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 87.104953 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 38 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 14.580881    \n",
            "Epoch 38 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 78.538887 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 39 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 14.110565    \n",
            "Epoch 39 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.922317 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 40 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 12.743785    \n",
            "Epoch 40 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 87.326030 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 41 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 12.252393    \n",
            "Epoch 41 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 80.520563 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 42 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 11.857259    \n",
            "Epoch 42 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 85.186420 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 43 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 11.412848    \n",
            "Epoch 43 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.224882 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 44 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 10.454084    \n",
            "Epoch 44 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 82.442330 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 45 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 9.893609     \n",
            "Epoch 45 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 81.641279 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 46 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 9.079215     \n",
            "Epoch 46 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 90.940769 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 47 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 8.648629     \n",
            "Epoch 47 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 84.164499 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 48 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 8.391582     \n",
            "Epoch 48 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 93.831054 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 49 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 7.944509     \n",
            "Epoch 49 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 83.514010 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 50 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 8.209893     \n",
            "Epoch 50 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 96.608152 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 51 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 7.834617     \n",
            "Epoch 51 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 92.332925 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 52 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 7.464173     \n",
            "Epoch 52 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 89.479139 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 53 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.935076     \n",
            "Epoch 53 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 96.554908 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 54 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 7.147773     \n",
            "Epoch 54 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 107.514350 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 55 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 7.460295     \n",
            "Epoch 55 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 99.737597 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 56 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.831072     \n",
            "Epoch 56 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.463246 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 57 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.994213     \n",
            "Epoch 57 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 103.111743 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 58 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.716016     \n",
            "Epoch 58 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.645310 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 59 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.768939     \n",
            "Epoch 59 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 93.574514 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 60 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.993258     \n",
            "Epoch 60 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 97.791638 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 61 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.248688     \n",
            "Epoch 61 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 107.142616 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 62 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.210697     \n",
            "Epoch 62 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 86.911651 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 63 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.569052     \n",
            "Epoch 63 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 95.120377 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 64 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.481698     \n",
            "Epoch 64 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 87.403488 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 65 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.386305     \n",
            "Epoch 65 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 92.209896 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 66 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.589337     \n",
            "Epoch 66 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 94.341426 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 67 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.343504     \n",
            "Epoch 67 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 113.737889 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 68 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 6.582925     \n",
            "Epoch 68 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 103.325857 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "Epoch 69 |   Training | Elapsed Time: 0:00:10 | Steps: 118 | Loss: 5.972485     \n",
            "Epoch 69 | Validation | Elapsed Time: 0:00:00 | Steps: 34 | Loss: 99.150500 | Dataset: /content/jw/data1/dev/dev.csv\n",
            "I FINISHED optimization in 0:13:22.875838\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1205 06:50:02.461742 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/jw/result/checkpoint/best_dev-2714\n",
            "I1205 06:50:02.463162 140438052673408 saver.py:1280] Restoring parameters from /content/jw/result/checkpoint/best_dev-2714\n",
            "I Restored variables from best validation checkpoint at /content/jw/result/checkpoint/best_dev-2714, step 2714\n",
            "Testing model on /content/jw/data1/test/test.csv\n",
            "Test epoch | Steps: 17 | Elapsed Time: 0:00:05                                  \n",
            "Test on /content/jw/data1/test/test.csv - WER: 0.723810, CER: 0.521672, loss: 78.063721\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.450000, loss: 46.429226\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apki_beti_theek_hogi.wav\n",
            " - src: \"apki beti theek hogi\"\n",
            " - res: \"apke lete ho koi\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.566667, loss: 71.595711\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apka_cashless_payment_hojayega.wav\n",
            " - src: \"apka cashless payment hojayega\"\n",
            " - res: \"apka ke se aa hoga\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.620690, loss: 72.081741\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/konsa_cheez_aapke_aaspass_hai.wav\n",
            " - src: \"konsa cheez aapke aaspass hai\"\n",
            " - res: \"aa aa ke aa aa \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.703704, loss: 72.315048\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/haanji_mera_naam_hai_munaji.wav\n",
            " - src: \"haanji mera naam hai munaji\"\n",
            " - res: \"aa aa hie \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.812500, loss: 76.253151\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/transaction_toh_totally_hojayega.wav\n",
            " - src: \"transaction toh totally hojayega\"\n",
            " - res: \"at the\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.823529, loss: 79.093567\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/adtalish_haazar_mein_kuch_nahi_hog.wav\n",
            " - src: \"adtalish haazar mein kuch nahi hog\"\n",
            " - res: \"so agar \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.857143, CER: 0.704545, loss: 136.423492\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/mujhe_maleria_ke_uppar_treatment_nahi_chaiye.wav\n",
            " - src: \"mujhe maleria ke uppar treatment nahi chaiye\"\n",
            " - res: \"age liye ke get hai \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.833333, CER: 0.583333, loss: 96.567284\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apka_homeopathy_treatment_haspatal_mein_hojayega.wav\n",
            " - src: \"apka homeopathy treatment haspatal mein hojayega\"\n",
            " - res: \"apka both the ten rehega\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.800000, CER: 0.461538, loss: 111.910141\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apke_angioplasty_surgery_treatment_ke_liye_mere_ko_contact_karoge.wav\n",
            " - src: \"apke angioplasty surgery treatment ke liye mere ko contact karoge\"\n",
            " - res: \"apke liye mere ten surgery ten ki liye contact kar \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.800000, CER: 0.632653, loss: 127.640160\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/sir_apka_location_mere_ko_samajh_nahi_aa_raha_hai.wav\n",
            " - src: \"sir apka location mere ko samajh nahi aa raha hai\"\n",
            " - res: \"apka ke mere kar agar \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.666667, CER: 0.428571, loss: 62.267136\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/sir_apka_mobile_recharge_karoge_toh.wav\n",
            " - src: \"sir apka mobile recharge karoge toh\"\n",
            " - res: \"apka mobile ke karte ho\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.625000, CER: 0.471698, loss: 94.024124\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apke_liye_magma_insurance_company_mein_claim_hojayega.wav\n",
            " - src: \"apke liye magma insurance company mein claim hojayega\"\n",
            " - res: \"apke liye magma ke liye mein ke ko ga\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.600000, CER: 0.555556, loss: 44.554607\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apka_address_hai_email_mein.wav\n",
            " - src: \"apka address hai email mein\"\n",
            " - res: \"apka isliye mein \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.600000, CER: 0.258065, loss: 58.193043\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/iskeliye_mein_claim_change_kiya.wav\n",
            " - src: \"iskeliye mein claim change kiya\"\n",
            " - res: \"isliye mein claim care ke\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.459459, loss: 57.111290\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/aagey_se_apka_appointment_subhe_lunga.wav\n",
            " - src: \"aagey se apka appointment subhe lunga\"\n",
            " - res: \"se apka appointment \"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.333333, CER: 0.363636, loss: 84.738518\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/apka_angiography_surgery_ke_liye_mere_ko_contact_karoge.wav\n",
            " - src: \"apka angiography surgery ke liye mere ko contact karoge\"\n",
            " - res: \"apka as se ke liye ko contact karoge\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.000000, CER: 0.000000, loss: 35.885094\n",
            " - wav: file:///content/jw/voices_recorded/test_data/sehefali/isliye_mein_aapke_liye_karunga.wav\n",
            " - src: \"isliye mein aapke liye karunga\"\n",
            " - res: \"isliye mein aapke liye karunga\"\n",
            "--------------------------------------------------------------------------------\n",
            "I Exporting the model...\n",
            "WARNING:tensorflow:From DeepSpeech.py:704: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "W1205 06:50:08.221381 140438052673408 deprecation_wrapper.py:119] From DeepSpeech.py:704: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/jw/result/checkpoint/train-8260\n",
            "I1205 06:50:08.433904 140438052673408 saver.py:1280] Restoring parameters from /content/jw/result/checkpoint/train-8260\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1205 06:50:08.478054 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1205 06:50:08.478333 140438052673408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 12 variables.\n",
            "I1205 06:50:08.496011 140438052673408 graph_util_impl.py:311] Froze 12 variables.\n",
            "INFO:tensorflow:Converted 12 variables to const ops.\n",
            "I1205 06:50:08.518634 140438052673408 graph_util_impl.py:364] Converted 12 variables to const ops.\n",
            "I Models exported at /content/jw/result/export_data/\n",
            "+ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlATuaSb707E",
        "colab_type": "text"
      },
      "source": [
        "#Testing the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T684hiVHSYP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 777 /content/jw/utilities/test_train_script/test_deepspeech.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yGjKFhZ2kCi",
        "colab_type": "code",
        "outputId": "ea11e0ff-6586-4687-c0dd-998d9cef5d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "!/content/jw/utilities/test_train_script/test_deepspeech.sh"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+ deepspeech --model /content/jw/result/export_data/output_graph.pb --lm /content/jw/lmbinary/lm.binary --trie /content/jw/trie/trie --audio /content/jw/voices_recorded/test_data/sehefali/adtalish_haazar_mein_kuch_nahi_hog.wav\n",
            "Loading model from file /content/jw/result/export_data/output_graph.pb\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.0-0-g6d43e21\n",
            "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
            "2019-12-05 07:07:54.714500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-12-05 07:07:54.715933: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-05 07:07:54.736155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.737212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-05 07:07:54.737263: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
            "2019-12-05 07:07:54.737361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.738327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.739160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-12-05 07:07:54.918197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-05 07:07:54.918257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-12-05 07:07:54.918271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-12-05 07:07:54.918446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.919209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.919932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-05 07:07:54.920619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-05 07:07:54.920667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10787 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Loaded model in 0.231s.\n",
            "Loading language model from files /content/jw/lmbinary/lm.binary /content/jw/trie/trie\n",
            "Loaded language model in 0.000226s.\n",
            "Running inference.\n",
            "adtalish as haazar mein ki ho nahi hog\n",
            "Inference took 0.637s for 4.226s audio file.\n",
            "+ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ukd8etYk1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}